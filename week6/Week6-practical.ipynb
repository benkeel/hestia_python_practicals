{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current RoadMap\n",
    "### Week 6: Advanced Pandas with data cleaning.\n",
    "* Loading data and cleaning\n",
    "* Filerting, grouping and plotting data\n",
    "\n",
    "### Week 7: Pulling it all together \n",
    "* json through pandas through plotting through saving updated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load in data + check the data\n",
    "Let's start by loading in and checking the cleanliness of dataset from Hestia..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the libraries we require for today\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use pandas to load in Excel data\n",
    "If this does not work, use: !pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Maize data from Hestia \n",
    "df = pd.read_excel(\"MaizePig.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, the data looks a little messy (265 columns is quite a lot!) and the column names are not lined up correctly. Obviously, we may just go into Excel and fix this manually, but I will also show you how to clean this using Python directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨ TASK\n",
    "We've looked at the header, and can see there is clearly problems. In the cell below look at the footer of the data to see if there is any other obvious issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at some summary statistics of the data, this will give us some indication about missing data and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the column names are being put as a seperate row, this is a common issue with Excel sheets from different sources. Before working with this data we need to fix this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning data in python \n",
    "From first look (and some investigation in Excel), it looks like we need to combine the first two rows ~, and maybk if we need to change some of the data types, for example strings to integers.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open in excel to view problems and get an idea of what cleaning needs to be done. First row has useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, let's look at the columns without these Unnamed columns.   ~\n",
    "We can achieve this reduced view with list comprehension and ask the list not to include the term 'Unnamed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col_name for col_name in list(df.columns.unique()) if 'Unnamed' not in col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's still a problem here, so let's get only the useful information from rows 1 and 2 but need to think of a way to combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨ TASK\n",
    "Look at unique entries in row 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that we need to make new formatted column names which are a combination of row 1 and 2, discarding the original column names (row 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " changing '-' to na/none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash = df.iloc[0][1]\n",
    "dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.replace()` method to replace the dash with np.nan (which is float type). Doing this will later allow us to use the `.dropna()` method, which drops all NaN values. Remember NaN means Not a Number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(dash, np.nan) # using numpy NaN so it works with summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the first two rows, as these look like they have our column names in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = df.iloc[0]\n",
    "row2 = df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 5 unique values to check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1.unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row2.unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create a combined list of new column names based on an assumption that if the column name is not in row1, it will be in row 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_rows = []\n",
    "for idx, item in enumerate(row1):\n",
    "    # The below condition will look for NaN and empty values\n",
    "    if item == item:\n",
    "        combined_rows.append(item)\n",
    "    else:\n",
    "        combined_rows.append(row2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check they are the same length\n",
    "len(combined_rows) == len(row1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then assign the `columns` property to this new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = combined_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now drop those first two rows, as we have already gotten the info from them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look for missing data by looking at count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly too much information, lets reduce data to just the important stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Removing unwanted columns\n",
    "Our data has quite a lot of information in it (265 columns). Let's look at how you would create a subset...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of `desired_cols` to subset the data by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cols = ['HH_ID', 'site.region.name', 'Area of sample parcel  (acres)',\\\n",
    "                'Price of seed planted (MMK)', 'Quantity of crop harvested (kg)',\\\n",
    "                'Quantity of crop sold (kg)', 'Total value of crop sold (MMK)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df = df[desired_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, now we have duplicates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.columns.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have googled a solution for removing duplicate columns (this is not perfect, but serves as a quick fix).\n",
    "I found this answer here: https://stackoverflow.com/questions/32041245/fast-method-for-removing-duplicate-columns-in-pandas-dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df = maize_df.loc[:,~maize_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some of the columns are misnamed, e.g. price is in dollars and MMK but called the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've selected some columns of interest, let's simplify some of the column names... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_col_names = {'HH_ID':'ID', 'site.region.name':'Region'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.rename` will let us rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df = maize_df.rename(columns=simplified_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's convert all of the numeric data to float types for later calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show us that our data is all object types \n",
    "maize_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that these are our numeric data types\n",
    "list(maize_df.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(maize_df.columns[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a built-in function that converts data from object to numeric, let's use that... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in numeric_cols:\n",
    "    maize_df[num_col] = pd.to_numeric(maize_df[num_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data types have changed\n",
    "maize_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* you can also achieve this without a for loop using the .apply() method `maize_df = maize_df[numeric_cols].apply(pd.to_numeric)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Imputing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with at least one NaN value\n",
    "columns_with_nan = maize_df.columns[maize_df.isnull().any()].tolist()\n",
    "columns_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several rows with NaN in multiple columns, lets drop them if they are NaN in 4 out of 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df = maize_df.dropna(subset=maize_df.columns[maize_df.isnull().sum() >= 4], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = maize_df[maize_df[columns_with_nan[0]].isnull()]\n",
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = maize_df[columns_with_nan[0]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df[columns_with_nan[0]].fillna(mean_value, inplace=True)\n",
    "maize_df[maize_df['ID'] == 65026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = maize_df[maize_df[columns_with_nan[1]].isnull()]\n",
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case for quantity harvested lets set it to the quantity sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df[columns_with_nan[1]].fillna(maize_df['Quantity of crop sold (kg)'], inplace=True)\n",
    "maize_df.iloc[rows_with_nan.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = maize_df[maize_df[columns_with_nan[2]].isnull()]\n",
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = maize_df[maize_df[columns_with_nan[2]].isnull()]\n",
    "\n",
    "maize_df[columns_with_nan[2]].fillna(maize_df['Quantity of crop harvested (kg)'], inplace=True)\n",
    "maize_df.iloc[rows_with_nan.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last row is tricky, any sugestions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = maize_df[maize_df[columns_with_nan[3]].isnull()]\n",
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My idea: find the average price the crops were sold for from other columns and then replace quantity harvested x average priice sold for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Average price sold for'] =  maize_df['Total value of crop sold (MMK)'] / maize_df['Quantity of crop harvested (kg)'] \n",
    "maize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price = maize_df['Average price sold for'].mean()\n",
    "mean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df[columns_with_nan[3]].fillna(maize_df['Quantity of crop sold (kg)']*mean_price, inplace=True)\n",
    "maize_df.iloc[rows_with_nan.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "\n",
    "Now employ an imputing strategy for NaN values in 'Average price sold for'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summary statistics + basic plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Quantity of crop harvested (kg)'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Quantity of crop sold (kg)'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily combine plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Quantity of crop harvested (kg)'].plot()\n",
    "maize_df['Quantity of crop sold (kg)'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above plots are a little messy, let's take a subset of data.  \n",
    "In the example below, we take rows where the price of seeds are above a certain limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricey_maize_df = maize_df.loc[maize_df['Price of seed planted (MMK)'] > 7500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨ TASK\n",
    "Look at, get some summary statistics for, and plot this new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "Pandas Series also provide a `.hist` method for histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Area of sample parcel  (acres)'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some smaller bins\n",
    "bins_to_use = np.arange(0, 50, 1)\n",
    "bins_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Area of sample parcel  (acres)'].hist(bins=bins_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of matplotlib.pyplot (plt)\n",
    "Matplotlib.pyplot (here loaded in as `plt`), open up some tools for labelling and controlling figures returned by Pandas.\n",
    "This includes allowing us to set titles, labels for axes, sizing of figure, background colour etc.\n",
    "For now, I will show you a very basic and well formatted way of using plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1) # This line is something you will grow used to over time. It sets the figure and axes of a plot \n",
    "maize_df['Area of sample parcel  (acres)'].hist(bins=bins_to_use, ax=ax) # We pass the argument ax=ax to set the location of the plot\n",
    "\n",
    "## Set the title, and axes labels.\n",
    "ax.set_title(\"Area of Sample Parcel\")\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_xlabel(\"Area size (acres)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨ Bigger TASK\n",
    "Let's use what we have learnt to look and plot some derived information from our data.\n",
    "Let's calculate the total cost of *the difference* between the crop sold and harvested.\n",
    "\n",
    "*Advice:* make sure you use multiple cells to seperate the tasks and keep the code clean\n",
    "\n",
    "##### Steps\n",
    "1. Create a new column `Crop difference (kg)` that is the quantity of crop harvested minus the quantity of crop sold.\n",
    "2. Convert this column to a difference using `abs()` (google if unsure)\n",
    "3. Convert the new column from kg to grams and calculate the price (in MMK) of each gram lost (let's assume that `Price of seed planted (MMK)` is for 1g). \n",
    "4. Save this a new column e.g. `Total cost of crop difference (MMK)`\n",
    "5. Plot a histogram and view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Locating items / filtering / sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some of the data is incorrect as there is negative crops lost after harvest, lets investigate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column\n",
    "maize_df['Crop lost after harvest (kg)'] = maize_df['Quantity of crop harvested (kg)']  - maize_df['Quantity of crop sold (kg)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's look at values less than 0 kg\n",
    "maize_df[maize_df['Crop lost after harvest (kg)'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly incorrect and as we imputed values with the value in the other column the difference should be 0. For these cases we can do one of two things: \n",
    "1. drop the rows\n",
    "2. replace the difference with 0 \n",
    "\n",
    "What seems more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "\n",
    "employ your prefered strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the best performing farms, i.e. the farms which had the highest total value sold and the highest percentage crops harvested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_to_use = np.arange(0, 100000, 1000)\n",
    "bins_to_use\n",
    "maize_df['Quantity of crop harvested (kg)'].hist(bins=bins_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df[maize_df['Quantity of crop harvested (kg)']>10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "*Advice:* make sure you use multiple cells to seperate the tasks and keep the code clean\n",
    "\n",
    "Make new column with percentage of crops lost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "\n",
    "Find the well performing farms with a low percentage (10%) of crops lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling\n",
    "For many statistical applications you may need to use sampling when you have uneven categories of things. Pandas provides a very simple solution to sampling with the `.sample()` method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Grouping / pivoting + plotting\n",
    "Finally, we will briefly cover more advanced pandas methods for handling and grouping data. \n",
    "Firstly `.groupby()` which will allow us to group categorical variables i.e. such as Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the regional mean values\n",
    "maize_df.groupby('Region').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "In a new cell below, save a new variable `regional_means` which is a groupby of the Regional means and then make a barplot of \"Price of seed planted (MMK)\". Which region planted the most expensive seeds on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we've looked at the regional mean, what if we wanted to get a sum of a column by region? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sum of only the total crop sold values (we can use the .agg function to only get this value)\n",
    "crops_sold_by_region = maize_df.groupby('Region').agg({'Total value of crop sold (MMK)':'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you wanted the sum of one column and the mean of another the syntax would be like:  \n",
    "`df.groupby('col').agg({'col1':'sum', 'col2':'mean'})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_sold_by_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_sold_by_region.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib.pyplot (plt) to clean up and make this figure a little nicer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 3))\n",
    "crops_sold_by_region.plot(marker='s', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "In the cell above, add a title, y and x label.\n",
    "\n",
    "*Remember:* Google may help\n",
    "\n",
    "**Further Tasks** Set the font size of the title and axes labels. \n",
    "Also look at changing the markers to circles and the color of line to black...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "Another form of data handling that pandas opens up is pivoting with `.pivot()`.\n",
    "\n",
    "Firstly, let's get something worthwhile pivoting the data on. Let's look at the influence of groups of area size to groups of harvest amount i.e. can we prove with this data that larger plot sizes mean more harvest in kg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the 33rd and 66th percentile as cut off points for our groups. We use pandas inbuilt function `.quantile` to get these values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the 33rd and 66th percentile values for area sizes\n",
    "maize_df['Area of sample parcel  (acres)'].quantile([0.33, 0.66])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a simple function that we can `.apply` to our dataset to label the data based on these quantile values of 1.5 and 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data_based_on_area(row):\n",
    "    # Simple function to label data in Area of sample parcel column\n",
    "    if row['Area of sample parcel  (acres)'] > 3:\n",
    "        return \"Area > 3 acres\"\n",
    "    elif row['Area of sample parcel  (acres)'] > 1.5 and row['Area of sample parcel  (acres)'] < 3:\n",
    "        return \"Area between 1.5 and 3 acres\"\n",
    "    else:\n",
    "        return \"Area < 1.5 acres\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data column\n",
    "maize_df['Area size group'] = maize_df.apply(label_data_based_on_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Area size group'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels look good, let's now do the same for the quantity of crop harvested..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the 33rd and 66th percentile values of crop harvested sizes\n",
    "maize_df['Quantity of crop harvested (kg)'].quantile([0.33, 0.66])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define another very similar function.\n",
    "For more efficient code, you want to avoid very similar functions (i.e. functions that share a large % of code), but for this example it is okay..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data_based_on_crop_harvested(row):\n",
    "    # Another simple function to label data.\n",
    "    if row['Quantity of crop harvested (kg)'] > 3260:\n",
    "        return \"Harvest > 3260 kg\"\n",
    "    elif row['Quantity of crop harvested (kg)'] > 1304 and row['Quantity of crop harvested (kg)'] < 3260:\n",
    "        return \"Harvest between 1304 and 3260 kg\"\n",
    "    else:\n",
    "        return \"Harvest < 1304 kg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this function and create a new column\n",
    "maize_df['Harvest size group'] = maize_df.apply(label_data_based_on_crop_harvested, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df['Harvest size group'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's pivot based on these two new columns and see what we get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df_harvest_area_pivot = maize_df.pivot(index='ID', columns='Harvest size group', values='Area size group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a breakdown of Harvest size to Area size\n",
    "maize_df_harvest_area_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the values of each column with `.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df_harvest_area_pivot['Harvest < 1304 kg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_df_harvest_area_pivot['Harvest > 3260 kg'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤¨TASK\n",
    "Have a play around and determine whether you could say that one size of area is more efficient for quantity of harvest than the others based only on the labels we have created here. \n",
    "\n",
    "*Hint:* Perhaps use .sample to create equally sized subsets, as these three categories have different amounts of values\n",
    "\n",
    "**FURTHER TASK** Create a visualisation to show this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
